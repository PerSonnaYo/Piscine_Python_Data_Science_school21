{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/day-of-week-not-scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.88757\n",
      "precision is 0.89267\n",
      "recall is 0.88757\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(f\"accuracy is {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"precision is {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.89053\n",
      "precision is 0.89262\n",
      "recall is 0.89053\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=22, class_weight='balanced', random_state=21, criterion='gini')\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print(f\"accuracy is {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"precision is {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.92899\n",
      "precision is 0.93009\n",
      "recall is 0.92899\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=28, random_state=21, criterion='gini')\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(f\"accuracy is {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"precision is {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svc',\n",
       "                              SVC(C=10, gamma='auto', probability=True,\n",
       "                                  random_state=21)),\n",
       "                             ('tree',\n",
       "                              DecisionTreeClassifier(class_weight='balanced',\n",
       "                                                     max_depth=22,\n",
       "                                                     random_state=21)),\n",
       "                             ('forest',\n",
       "                              RandomForestClassifier(max_depth=28,\n",
       "                                                     n_estimators=50,\n",
       "                                                     random_state=21))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vot = VotingClassifier([('svc', svc), ('tree', dtc), ('forest', rfc)]  )\n",
    "vot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92308\n",
      "Precision: 0.92399\n",
      "Recall: 0.92308\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ................... (3 of 3) Processing forest, total=   0.1s\n",
      "[Voting] ..................... (2 of 3) Processing tree, total=   0.0s\n",
      "[Voting] ...................... (1 of 3) Processing svc, total=   0.7s\n",
      "Accuracy: 0.92308\n",
      "Precision: 0.92399\n",
      "Recall: 0.92308\n"
     ]
    }
   ],
   "source": [
    "vot1 = VotingClassifier([('svc', svc), ('tree', dtc), ('forest', rfc)], n_jobs=-1, verbose=True  )\n",
    "vot1.fit(X_train, y_train)\n",
    "y_pred1 = vot1.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred1):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred1, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred1, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing tree, total=   0.0s\n",
      "[Voting] ................... (3 of 3) Processing forest, total=   0.1s\n",
      "[Voting] ...................... (1 of 3) Processing svc, total=   0.7s\n",
      "Accuracy: 0.90533\n",
      "Precision: 0.90793\n",
      "Recall: 0.90533\n"
     ]
    }
   ],
   "source": [
    "vot1 = VotingClassifier([('svc', svc), ('tree', dtc), ('forest', rfc)], n_jobs=-1 ,weights=[2,1,1], verbose=True, voting='soft' )\n",
    "vot1.fit(X_train, y_train)\n",
    "y_pred1 = vot1.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred1):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred1, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred1, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing tree, total=   0.0s\n",
      "[Voting] ................... (3 of 3) Processing forest, total=   0.1s\n",
      "[Voting] ...................... (1 of 3) Processing svc, total=   0.8s\n",
      "Accuracy: 0.91716\n",
      "Precision: 0.91895\n",
      "Recall: 0.91716\n"
     ]
    }
   ],
   "source": [
    "vot1 = VotingClassifier([('svc', svc), ('tree', dtc), ('forest', rfc)], n_jobs=-1 ,weights=[1,1,2], verbose=True, voting='soft' )\n",
    "vot1.fit(X_train, y_train)\n",
    "y_pred1 = vot1.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred1):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred1, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred1, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ..................... (2 of 3) Processing tree, total=   0.0s\n",
      "[Voting] ................... (3 of 3) Processing forest, total=   0.1s\n",
      "[Voting] ...................... (1 of 3) Processing svc, total=   0.8s\n",
      "Accuracy: 0.92899\n",
      "Precision: 0.93017\n",
      "Recall: 0.92899\n"
     ]
    }
   ],
   "source": [
    "vot1 = VotingClassifier([('svc', svc), ('tree', dtc), ('forest', rfc)], n_jobs=-1 , verbose=True, weights=[1,2,2] )\n",
    "vot1.fit(X_train, y_train)\n",
    "y_pred1 = vot1.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred1):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred1, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred1, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90828\n",
      "Precision: 0.91091\n",
      "Recall: 0.90828\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=50, n_jobs=-1, random_state=21)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53846\n",
      "Precision: 0.47375\n",
      "Recall: 0.53846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=20, n_jobs=-1, max_features=10)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89645\n",
      "Precision: 0.90063\n",
      "Recall: 0.89645\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=40, n_jobs=-1, random_state=6, bootstrap=False)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82840\n",
      "Precision: 0.84572\n",
      "Recall: 0.82840\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=60, n_jobs=-1, random_state=21, warm_start=True, bootstrap_features=True)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90533\n",
      "Precision: 0.90843\n",
      "Recall: 0.90533\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=20, n_jobs=-1, random_state=15, warm_start=True)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91124\n",
      "Precision: 0.91379\n",
      "Recall: 0.91124\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=100, n_jobs=-1, oob_score=True, random_state=50)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "# print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = StackingClassifier(\n",
    "    [('svc', svc), ('tree', dtc), ('forest', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'cv': [2, 3, 4, 5, 6, 7], 'passthrough': [True, False]}\n",
    "\n",
    "gs = GridSearchCV(stacking, param_grid, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/Users/latkins/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': 6, 'passthrough': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91716\n",
      "Precision: 0.92049\n",
      "Recall: 0.91716\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92899\n",
      "Precision: 0.93017\n",
      "Recall: 0.92899\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = vot1.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred1):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred1, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred1, average='weighted'):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x12caf1dd0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(vot1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/model1.joblib']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vot1, '../data/model1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
