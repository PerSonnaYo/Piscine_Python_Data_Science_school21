{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4           0           0            0   \n",
       "1     -0.756764 -2.562352          4           0           0            0   \n",
       "2     -0.724861 -2.562352          4           0           0            0   \n",
       "3     -0.692958 -2.562352          4           0           0            0   \n",
       "4     -0.661055 -2.562352          4           0           0            0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3           0           0            0   \n",
       "1682  -0.629151  0.945382          3           0           1            0   \n",
       "1683  -0.597248  0.945382          3           0           1            0   \n",
       "1684  -0.565345  0.945382          3           0           1            0   \n",
       "1685  -0.533442  0.945382          3           0           1            0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0               0            0            0            0  ...              0   \n",
       "1               0            0            0            0  ...              0   \n",
       "2               0            0            0            0  ...              0   \n",
       "3               0            0            0            0  ...              0   \n",
       "4               0            0            0            0  ...              0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681            0            0            0            0  ...              0   \n",
       "1682            0            0            0            0  ...              0   \n",
       "1683            0            0            0            0  ...              0   \n",
       "1684            0            0            0            0  ...              0   \n",
       "1685            0            0            0            0  ...              0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681              0               0               0               0   \n",
       "1682              0               0               0               0   \n",
       "1683              0               0               0               0   \n",
       "1684              0               0               0               0   \n",
       "1685              0               0               0               0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                   0               0               0                0   \n",
       "1                   0               0               0                0   \n",
       "2                   0               0               0                0   \n",
       "3                   0               0               0                0   \n",
       "4                   0               0               0                0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681                0               0               0                1   \n",
       "1682                0               0               0                1   \n",
       "1683                0               0               0                1   \n",
       "1684                0               0               0                1   \n",
       "1685                0               0               0                1   \n",
       "\n",
       "      labname_project1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1681                 0  \n",
       "1682                 0  \n",
       "1683                 0  \n",
       "1684                 0  \n",
       "1685                 0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dayofweek.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(fit_intercept=False, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(estimator, X, y, n_splits=10):\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    cv = StratifiedKFold(n_splits=n_splits)\n",
    "    for train, valid in cv.split(X, y):\n",
    "        estimator.fit(X.iloc[train], y.iloc[train])\n",
    "        y_train_pred = estimator.predict(X.iloc[train])\n",
    "        y_valid_pred = estimator.predict(X.iloc[valid])\n",
    "        train_scores.append(accuracy_score(y.iloc[train], y_train_pred))\n",
    "        valid_scores.append(accuracy_score(y.iloc[valid], y_valid_pred))\n",
    "    for i in range(len(train_scores)):\n",
    "        print(f'train -  {train_scores[i]:.5f}   |   valid -  {valid_scores[i]:.5f}')\n",
    "    print(f'Average accuracy on crossval is {np.mean(valid_scores):.5f}')\n",
    "    print(f'Std is {np.std(valid_scores):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.62902   |   valid -  0.59259\n",
      "train -  0.64633   |   valid -  0.62963\n",
      "train -  0.63479   |   valid -  0.56296\n",
      "train -  0.65622   |   valid -  0.61481\n",
      "train -  0.63397   |   valid -  0.57778\n",
      "train -  0.64056   |   valid -  0.59259\n",
      "train -  0.64138   |   valid -  0.65926\n",
      "train -  0.65952   |   valid -  0.56296\n",
      "train -  0.64333   |   valid -  0.59701\n",
      "train -  0.63674   |   valid -  0.62687\n",
      "Average accuracy on crossval is 0.60165\n",
      "Std is 0.02943\n",
      "CPU times: total: 1.5 s\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flman\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(fit_intercept=False, random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear', 'saga']},\n",
       "                         {'penalty': ['l1', 'l2', 'none'], 'solver': ['saga']},\n",
       "                         {'penalty': ['l2', 'none'],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'sag']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "              {'solver': ['liblinear', 'saga'], 'penalty': ['l1', 'l2']},\n",
    "              {'solver': ['saga'], 'penalty': ['l1', 'l2', 'none']},\n",
    "              {'solver': ['newton-cg', 'lbfgs', 'sag'], 'penalty': ['l2', 'none']}]\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'none', 'solver': 'sag'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6313314057551975"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', probability=True, random_state=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.70486   |   valid -  0.65926\n",
      "train -  0.69662   |   valid -  0.75556\n",
      "train -  0.69415   |   valid -  0.62222\n",
      "train -  0.70239   |   valid -  0.65185\n",
      "train -  0.69085   |   valid -  0.65185\n",
      "train -  0.68920   |   valid -  0.64444\n",
      "train -  0.69250   |   valid -  0.72593\n",
      "train -  0.70074   |   valid -  0.62222\n",
      "train -  0.69605   |   valid -  0.61940\n",
      "train -  0.71087   |   valid -  0.63433\n",
      "Average accuracy on crossval is 0.65871\n",
      "Std is 0.04359\n",
      "CPU times: total: 6.36 s\n",
      "Wall time: 7.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(svc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear', probability=True, random_state=21),\n",
       "             n_jobs=-1, param_grid={'C': [15, 40, 60, 100, 150]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [15, 40, 60, 100, 150]}\n",
    "gs = GridSearchCV(svc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7403662398457937"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.81039   |   valid -  0.74074\n",
      "train -  0.77741   |   valid -  0.74074\n",
      "train -  0.83347   |   valid -  0.70370\n",
      "train -  0.79720   |   valid -  0.76296\n",
      "train -  0.82440   |   valid -  0.75556\n",
      "train -  0.80379   |   valid -  0.68889\n",
      "train -  0.80709   |   valid -  0.76296\n",
      "train -  0.80132   |   valid -  0.65926\n",
      "train -  0.80807   |   valid -  0.75373\n",
      "train -  0.80478   |   valid -  0.68657\n",
      "Average accuracy on crossval is 0.72551\n",
      "Std is 0.03562\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(dtc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(max_depth=10, random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24]),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'splitter': ['best', 'random'],\n",
    "              'max_depth': np.arange(2, 25)}\n",
    "gs = GridSearchCV(dtc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 21, 'splitter': 'random'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716590940382762"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  0.96455   |   valid -  0.88148\n",
      "train -  0.96208   |   valid -  0.91852\n",
      "train -  0.96785   |   valid -  0.86667\n",
      "train -  0.96455   |   valid -  0.89630\n",
      "train -  0.96538   |   valid -  0.91111\n",
      "train -  0.96538   |   valid -  0.88148\n",
      "train -  0.97115   |   valid -  0.91852\n",
      "train -  0.96867   |   valid -  0.85185\n",
      "train -  0.97364   |   valid -  0.88060\n",
      "train -  0.97941   |   valid -  0.86567\n",
      "Average accuracy on crossval is 0.88722\n",
      "Std is 0.02204\n",
      "CPU times: total: 1.75 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=14, n_estimators=50,\n",
       "                                              random_state=21),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': array([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
       "        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
       "        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
       "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "       115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "       128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "       141, 142, 143, 144, 145, 146, 147, 148, 149])},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'max_depth': np.arange(15, 30),\n",
    "              'n_estimators': np.arange(50, 150)}\n",
    "gs = GridSearchCV(rfc, param_grid, scoring='accuracy', n_jobs=-1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 27, 'max_features': 'auto', 'n_estimators': 147}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042929918766351"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319526627218935"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x135804e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(gs.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs.best_estimator_, '../data/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
